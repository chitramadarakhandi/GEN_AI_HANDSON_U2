{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c75e5c1-966a-444c-ac67-18513e1c54ca",
   "metadata": {},
   "source": [
    "etrieval Augmented Generation (RAG) solves this by retrieving relevant data and injecting it into the prompt.\n",
    "\n",
    "In this notebook, we will learn:\n",
    "\n",
    "Embeddings: Representing text as vectors.\n",
    "Vector Stores: Storing and searching vectors (FAISS).\n",
    "Naïve RAG: The standard Retrieval -> Augment -> Generate pipeline.\n",
    "Indexing Challenges: Deep dive into how vector databases search efficiently (Flat, IVF, HNSW, PQ)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbf306-262d-4ccc-9a02-3f0f08ac6a5f",
   "metadata": {},
   "source": [
    "STEP 1:\n",
    "Embeddings:\n",
    "An embedding is a translation from Words to Lists of Numbers (Vectors), such that similar words represent close numbers.\n",
    "\n",
    "The Process (Flowchart)\n",
    "graph LR\n",
    "    A[\"Input Text ('Apple')\"] -->|Tokenization| B[\"Tokens (101, 255)\"]\n",
    "    B -->|Embedding Model| C[\"Vector List ([0.1, -0.5, 0.9...])\"]\n",
    "    C -->|Store| D[\"Vector Database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732d665-464d-480d-b5f8-8f0a0af20990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9806fd2e-2a36-4f33-9ef2-bd7c5a6bcac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "040e5b24f68a447f9b0f29211267ea88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prajw\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\prajw\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6ca936a46b429081f33a692b649f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c30ba02d2b4397a17758ad2e841cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a411e7fc2b94860b0e65412c6e8f068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4407d26b38d4a2b94dcfd73c96529f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb00ba1a9b91404cbc8b289c14ad9434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup\n",
    "%pip install python-dotenv --upgrade --quiet langchain langchain-huggingface sentence-transformers langchain-community\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Using a FREE, open-source model from Hugging Face\n",
    "# 'all-MiniLM-L6-v2' is small, fast, and very good for English.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9424396-47ce-4288-9ead-2f77110af881",
   "metadata": {},
   "source": [
    "2. Viewing a Vector\n",
    "Let's see what the word \"Apple\" looks like to the machine.\n",
    "\n",
    "Conceptual Note: Dimensions\n",
    "The vector below has 384 dimensions (for MiniLM).\n",
    "\n",
    "Imagine a graph with X and Y axes (2 Dimensions). You can plot a point (x, y).\n",
    "Now imagine adding Z (3 Dimensions).\n",
    "Now imagine 384 axes.\n",
    "Each axis represents a feature (e.g., \"Is it a fruit?\", \"Is it red?\", \"Is it tech-related?\"). The numbers aren't random; they encode meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a3be3e-93cf-4f75-a0da-74265c14e034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality: 384\n",
      "First 5 numbers: [-0.006138490047305822, 0.031011775135993958, 0.06479357182979584, 0.01094149798154831, 0.0052671879529953]\n"
     ]
    }
   ],
   "source": [
    "vector = embeddings.embed_query(\"Apple\")\n",
    "\n",
    "print(f\"Dimensionality: {len(vector)}\")\n",
    "print(f\"First 5 numbers: {vector[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482535a-f382-4566-b208-7533672b83db",
   "metadata": {},
   "source": [
    "step 3:  Cosine Similarity\n",
    "How do we know if two vectors are close? We measure the Angle between them.\n",
    "\n",
    "Cosine Similarity Formula\n",
    " \n",
    "\n",
    "1.0: Arrows point in the Exact Same Direction (Identical).\n",
    "0.0: Arrows are Perpendicular (Unrelated).\n",
    "-1.0: Arrows point in Opposite Directions (Opposite).\n",
    "Experiment: Let's compare \"Cat\", \"Dog\", and \"Car\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b90d525-fa8b-4e45-be4c-2c6e9bf5b185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat vs Dog: 0.6606\n",
      "Cat vs Car: 0.4633\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "vec_cat = embeddings.embed_query(\"Cat\")\n",
    "vec_dog = embeddings.embed_query(\"Dog\")\n",
    "vec_car = embeddings.embed_query(\"Car\")\n",
    "\n",
    "print(f\"Cat vs Dog: {cosine_similarity(vec_cat, vec_dog):.4f}\")\n",
    "print(f\"Cat vs Car: {cosine_similarity(vec_cat, vec_car):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8fe669-85d7-40b0-97d7-501220cf48de",
   "metadata": {},
   "source": [
    "Analysis\n",
    "You should see that Cat & Dog score higher (e.g., ~0.8) than Cat & Car (e.g., ~0.3).\n",
    "This Mathematical Distance is the foundation of all Search engines and RAG systems.\n",
    "This is arguably the most important concept in modern AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d34d26-c243-4d42-8e13-daa305f966e6",
   "metadata": {},
   "source": [
    "Unit 2 - Part 4b: Naive RAG Pipeline\n",
    "1. Introduction: The Open-Book Test\n",
    "RAG (Retrieval-Augmented Generation) is just an Open-Book Test architecture.\n",
    "\n",
    "Retrieval: Find the right page in the textbook.\n",
    "Generation: Write the answer using that page.\n",
    "The Pipeline (Flowchart)\n",
    "graph TD\n",
    "    User[User Question] --> Retriever[Retriever System]\n",
    "    Retriever -->|Search Database| Docs[Relevant Documents]\n",
    "    Docs --> Combiner[Prompt Template]\n",
    "    User --> Combiner\n",
    "    Combiner -->|Full Prompt w/ Context| LLM[Gemini Model]\n",
    "    LLM --> Answer[Final Answer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a093d017-e684-4a6f-9d14-d4e088e410fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Google API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "%pip install python-dotenv --upgrade --quiet faiss-cpu langchain-huggingface sentence-transformers langchain-community\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# Using the same free model as Part 4a\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ff571-04f7-4e13-9b21-15f7ea8b9106",
   "metadata": {},
   "source": [
    "step 2\n",
    "The \"Knowledge Base\" (Grounding)\n",
    "LLMs hallucinate because they rely on \"parametric memory\" (what they learned during training). RAG introduces \"non-parametric memory\" (external facts).\n",
    "\n",
    "Let's define some facts the LLM definitely does not know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d26b41e6-5a63-4a9d-b495-f26d736dfd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "docs = [\n",
    "    Document(page_content=\"Ram's favorite food is Pizza with extra cheese.\"),\n",
    "    Document(page_content=\"The secret password to the lab is 'Blueberry'.\"),\n",
    "    Document(page_content=\"LangChain is a framework for developing applications powered by language models.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3a96a4-c14f-413a-9e8b-fff17b459fb3",
   "metadata": {},
   "source": [
    "3. Indexing ( Storing the knowledge)\n",
    "We use FAISS (Facebook AI Similarity Search) to store the embeddings. Think of FAISS as a super-fast librarian that organizes books by content, not title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cf93509-cefe-432a-84cd-660934087672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde167ff-725b-490f-bb9d-440619d7776a",
   "metadata": {},
   "source": [
    "4. The RAG Chain\n",
    "We use LCEL to stitch it together.\n",
    "\n",
    "Step 1: The retriever takes the question, converts it to numbers, and finds the closest document. Step 2: RunnablePassthrough holds the question. Step 3: The prompt combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7c34223-0df3-4a38-a0f9-df4d979ad3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The secret password to the lab is 'Blueberry'.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "template = \"\"\"\n",
    "Answer based ONLY on the context below:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "result = chain.invoke(\"What is the secret password?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8898f-b2c4-4797-b0d5-864e317a492e",
   "metadata": {},
   "source": [
    "Unit 2 - Part 4c: Deep Dive into Indexing Algorithms\n",
    "1. Introduction: The Scale Problem\n",
    "Comparing 1 vector against 10 vectors is fast. Comparing 1 vector against 100 Million vectors is slow.\n",
    "\n",
    "FAISS (Facebook AI Similarity Search) was built to solve this.\n",
    "\n",
    "The Trade-off Triangle\n",
    "You can pick 2:\n",
    "\n",
    "Speed (Query time)\n",
    "Accuracy (Recall)\n",
    "Memory (RAM usage)\n",
    "We will explore algorithms that optimize different corners of this triangle.\n",
    "\n",
    "FAISS\n",
    "To find similar items:\n",
    "Compare query with ALL vectors → VERY SLOW\n",
    "\n",
    "With FAISS:\n",
    "Use smart indexing → VERY FAST search\n",
    "\n",
    "FAISS = Toolbox\n",
    "IVF, Flat, HNSW = Tools inside the toolbox\n",
    "FAISS\n",
    "| Data Type       | Converted to vector using |\n",
    "| --------------- | ------------------------- |\n",
    "| Text            | BERT                      |\n",
    "| Image           | CLIP                      |\n",
    "| Audio           | Wav2Vec                   |\n",
    "| Medical records | ML models                 |\n",
    "Raw Data → ML Model → Embeddings → FAISS Index → Fast Search\n",
    "\n",
    "| Inside FAISS | Type              |\n",
    "| ------------ | ----------------- |\n",
    "| IndexFlatL2  | Brute force       |\n",
    "| IVF          | Clustering based  |\n",
    "| HNSW         | Graph based       |\n",
    "| PQ           | Compression based |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1bb35c4-7953-4ef0-8322-aefa7f2cbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Mock Data: 10,000 vectors of size 128\n",
    "d = 128\n",
    "nb = 10000\n",
    "xb = np.random.random((nb, d)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "865cbf2e-2e2e-49e2-b245-58d515e650be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57419246 0.67032593 0.8117177  0.3015775  0.5329976  0.93656397\n",
      " 0.13079847 0.89855385 0.7252274  0.70697194]\n"
     ]
    }
   ],
   "source": [
    "vector_0 = index.reconstruct(0)\n",
    "print(vector_0[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a6418-2902-4e63-8d43-56d630e68cb1",
   "metadata": {},
   "source": [
    "2. Flat Index (Brute Force)\n",
    "Concept: Check every single item.\n",
    "\n",
    "Algo: IndexFlatL2\n",
    "Pros: 100% Accuracy (Gold Standard).\n",
    "Cons: Slow (O(N)). Unusable at 1M+ vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41236381-b84d-4709-86ad-74e2d4d24380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat Index contains 10000 vectors\n",
      "Nearest vector indices: [[7202 7665 1813 9801 2081]]\n",
      "Distances: [[13.944866 15.118895 15.226116 15.274494 15.294832]]\n"
     ]
    }
   ],
   "source": [
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(xb)\n",
    "print(f\"Flat Index contains {index.ntotal} vectors\")\n",
    "xq = np.random.random((1, d)).astype('float32')\n",
    "k = 5\n",
    "D, I = index.search(xq, k)\n",
    "\n",
    "print(\"Nearest vector indices:\", I)\n",
    "print(\"Distances:\", D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d94f5e-c317-467a-a495-6d73cb036fa2",
   "metadata": {},
   "source": [
    "IVF (Inverted File Index)\n",
    "Concept: Clustering / Partitioning.\n",
    "\n",
    "Imagine looking for a book. Instead of checking every shelf, you go to the \"Sci-Fi\" section. Then you only search books in that section.\n",
    "\n",
    "How it works (Flowchart)\n",
    "graph TD\n",
    "    Data[All 1M Vectors] -->|Train| Clusters[1000 Cluster Centers (Centroids)]\n",
    "    Query[User Query] -->|Step 1| FindClosest[Find Closest Centroid]\n",
    "    FindClosest -->|Step 2| Search[Search ONLY vectors in that Cluster]\n",
    "Analogy: Voronoi Cells (Zip Codes). We only search the local zip code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2631179f-8f75-4fc4-8f4a-1a02906308c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 100 # How many 'zip codes' (clusters) we want\n",
    "quantizer = faiss.IndexFlatL2(d) # The calculator for distance\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "\n",
    "# We MUST train it first so it learns where the clusters are\n",
    "index_ivf.train(xb)\n",
    "index_ivf.add(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1eec4e0-b09f-43ed-9839-117f230b95ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is index trained? True\n",
      "Total vectors in index: 10000\n",
      "Number of clusters (nlist): 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Is index trained?\", index_ivf.is_trained)\n",
    "print(\"Total vectors in index:\", index_ivf.ntotal)\n",
    "print(\"Number of clusters (nlist):\", index_ivf.nlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dc5245a-5e87-4ab5-a0b3-8724283c32e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest indices: [[7545 6908 5141 7508 8635]]\n",
      "Distances: [[14.238964 14.576822 14.699944 14.912453 14.918861]]\n"
     ]
    }
   ],
   "source": [
    "index_ivf.nprobe = 5   # search in 5 clusters\n",
    "\n",
    "xq = np.random.random((1, d)).astype('float32')\n",
    "D, I = index_ivf.search(xq, 5)\n",
    "\n",
    "print(\"Nearest indices:\", I)\n",
    "print(\"Distances:\", D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "953a28a2-6144-4547-b456-4706183ae6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest indices: [[1591 5072 7665 9222 2997]]\n",
      "Distances: [[14.290031 14.958415 15.116154 15.228895 15.249875]]\n"
     ]
    }
   ],
   "source": [
    "index_ivf.nprobe = 5   # search in 5 clusters\n",
    "\n",
    "xq = np.random.random((1, d)).astype('float32')\n",
    "D, I = index_ivf.search(xq, 5)\n",
    "\n",
    "print(\"Nearest indices:\", I)\n",
    "print(\"Distances:\", D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed778ce8-fdce-4ed3-bfe8-a35d966917b1",
   "metadata": {},
   "source": [
    "4. HNSW (Hierarchical Navigable Small World)\n",
    "Concept: Six Degrees of Separation.\n",
    "\n",
    "Most data is connected. HNSW builds a Graph.\n",
    "\n",
    "Layer 0: Every point connects to neighbors.\n",
    "Layer 1: \"Express Highways\" connecting distant points.\n",
    "Analogy: Catching a flight. You don't fly Local -> Local -> Local. You fly Local -> HUB (Chicago) -> HUB (London) -> Local.\n",
    "\n",
    "Pros: Extremely fast retrieval.\n",
    "Cons: Heavier on RAM (needs to store the edges of the graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3562d51c-b4c2-4efb-a8fb-0853ebf40b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 16 # Number of connections per node (The 'Hub' factor)\n",
    "index_hnsw = faiss.IndexHNSWFlat(d, M)\n",
    "index_hnsw.add(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82edff39-c9cd-4354-8e65-ffd7b64865ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest indices: [[8502  364 2709 6073 3391]]\n",
      "Distances: [[13.399868  14.951712  15.054377  15.58529   15.6603565]]\n"
     ]
    }
   ],
   "source": [
    "xq = np.random.random((1, d)).astype('float32')\n",
    "\n",
    "D, I = index_hnsw.search(xq, 5)\n",
    "\n",
    "print(\"Nearest indices:\", I)\n",
    "print(\"Distances:\", D)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf44fd-56ec-4acc-8544-a75a1a7765b6",
   "metadata": {},
   "source": [
    "5. PQ (Product Quantization)\n",
    "Concept: Compression (Lossy).\n",
    "\n",
    "Do we need 32-bit float precision (0.123456789)? No. 0.12 is fine. PQ breaks the vector into chunks and approximates them.\n",
    "\n",
    "Analogy: 4K Video vs 480p Video.\n",
    "\n",
    "480p is blurry, but it's 10x smaller and faster to stream.\n",
    "Use PQ when you are RAM constrained (e.g., storing 1 Billion vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4554c2-ff1c-4842-8e52-65479daa9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PQ Compression complete. RAM usage minimized.\n"
     ]
    }
   ],
   "source": [
    "m = 8 # Split vector into 8 sub-vectors\n",
    "index_pq = faiss.IndexPQ(d, m, 8)\n",
    "index_pq.train(xb)\n",
    "index_pq.add(xb)\n",
    "print(\"PQ Compression complete. RAM usage minimized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d31b6-59be-4bf0-87a6-9d293ea0a13d",
   "metadata": {},
   "source": [
    "| Index | Speed     | Accuracy  | Memory   |\n",
    "| ----- | --------- | --------- | -------- |\n",
    "| Flat  | Slow      | 100%      | High     |\n",
    "| IVF   | Fast      | High      | Medium   |\n",
    "| HNSW  | Very Fast | Very High | High     |\n",
    "| PQ    | Very Fast | Medium    | Very Low |\n",
    "\n",
    "| Method | Think as        |\n",
    "| ------ | --------------- |\n",
    "| Flat   | Check All       |\n",
    "| IVF    | Go to Section   |\n",
    "| HNSW   | Travel via Hubs |\n",
    "| PQ     | Compress Data   |\n",
    "\n",
    "Flat → Exact but heavy\n",
    "IVF → Clustered search\n",
    "HNSW → Graph navigation\n",
    "PQ → Compressed storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9650d1ed-05ab-46ea-8ef6-1e8f8b28bc5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
